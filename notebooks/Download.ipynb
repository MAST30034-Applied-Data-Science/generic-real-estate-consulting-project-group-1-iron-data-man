{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee3751a3",
   "metadata": {},
   "source": [
    "## Scrape data from domain website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea194bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# built-in imports\n",
    "import re\n",
    "from json import dump\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# user packages\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d0e05e",
   "metadata": {},
   "source": [
    "## Scrape data sorted by highest price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "864aaa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "BASE_URL = \"https://www.domain.com.au\"\n",
    "N_PAGES = range(1, 51) # update this to your liking\n",
    "\n",
    "# begin code\n",
    "url_links = []\n",
    "property_metadata = defaultdict(dict)\n",
    "\n",
    "# generate list of urls to visit\n",
    "for page in N_PAGES:\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"}\n",
    "    url = BASE_URL + f\"/rent/vic/?sort=price-desc&page={page}\"\n",
    "    bs_object = BeautifulSoup(requests.get(url, headers=headers).text, \"html.parser\")\n",
    "\n",
    "    # find the unordered list (ul) elements which are the results, then\n",
    "    # find all href (a) tags that are from the base_url website.\n",
    "    index_links = bs_object \\\n",
    "        .find(\n",
    "            \"ul\",\n",
    "            {\"data-testid\": \"results\"}\n",
    "        ) \\\n",
    "        .findAll(\n",
    "            \"a\",\n",
    "            href=re.compile(f\"{BASE_URL}/*\") # the `*` denotes wildcard any\n",
    "        )\n",
    "\n",
    "    for link in index_links:\n",
    "        # if its a property address, add it to the list\n",
    "        if 'address' in link['class']:\n",
    "            url_links.append(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b57c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each url, scrape some basic metadata\n",
    "for property_url in url_links[1:]:\n",
    "    bs_object = BeautifulSoup(requests.get(property_url, headers=headers).text, \"html.parser\")\n",
    "\n",
    "    # looks for the header class to get property name\n",
    "    property_metadata[property_url]['name'] = bs_object \\\n",
    "        .find(\"h1\", {\"class\": \"css-164r41r\"}) \\\n",
    "        .text\n",
    "\n",
    "    # looks for the div containing a summary title for cost\n",
    "    property_metadata[property_url]['cost_text'] = bs_object \\\n",
    "        .find(\"div\", {\"data-testid\": \"listing-details__summary-title\"}) \\\n",
    "        .text\n",
    "\n",
    "    # looks for the div containing the number of bed, bathroom and parking area\n",
    "    property_metadata[property_url]['features'] = bs_object \\\n",
    "        .find(\"div\", {\"data-testid\": \"property-features-wrapper\"}) \\\n",
    "        .text\n",
    "    \n",
    "    # looks for the div containing the type of property\n",
    "    property_metadata[property_url]['type'] = bs_object \\\n",
    "        .find(\"div\", {\"data-testid\": \"listing-summary-property-type\"}) \\\n",
    "        .text\n",
    "    \n",
    "    # extract coordinates from the hyperlink provided\n",
    "    property_metadata[property_url]['coordinates'] = [\n",
    "        float(coord) for coord in re.findall(\n",
    "            r'destination=([-\\s,\\d\\.]+)', # use regex101.com here if you need to\n",
    "            bs_object \\\n",
    "                .find(\n",
    "                    \"a\",\n",
    "                    {\"target\": \"_blank\", 'rel': \"noopener noreferer\"}\n",
    "                ) \\\n",
    "                .attrs['href']\n",
    "        )[0].split(',')\n",
    "    ]\n",
    "\n",
    "    #property_metadata[property_url]['rooms'] = [\n",
    "    #    re.findall(r'\\d\\s[A-Za-z]+', feature.text)[0] for feature in bs_object \\\n",
    "    #        .find(\"div\", {\"data-testid\": \"property-features\"}) \\\n",
    "    #        .findAll(\"span\", {\"data-testid\": \"property-features-text-container\"})\n",
    "    #]\n",
    "\n",
    "    property_metadata[property_url]['desc'] = re \\\n",
    "        .sub(r'<br\\/>', '\\n', str(bs_object.find(\"p\"))) \\\n",
    "        .strip('</p >')\n",
    "\n",
    "# output to example json in data/raw/\n",
    "with open('../data/raw/highest_price.json', 'w') as f:\n",
    "    dump(property_metadata, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88be433b",
   "metadata": {},
   "source": [
    "## Scrape data sorted by Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cbe1f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "BASE_URL = \"https://www.domain.com.au\"\n",
    "N_PAGES = range(1, 51) # update this to your liking\n",
    "\n",
    "# begin code\n",
    "url_links = []\n",
    "property_metadata = defaultdict(dict)\n",
    "\n",
    "# generate list of urls to visit\n",
    "for page in N_PAGES:\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"}\n",
    "    url = BASE_URL + f\"/rent/vic/?sort=default-desc&page={page}\"\n",
    "    bs_object = BeautifulSoup(requests.get(url, headers=headers).text, \"html.parser\")\n",
    "\n",
    "    # find the unordered list (ul) elements which are the results, then\n",
    "    # find all href (a) tags that are from the base_url website.\n",
    "    index_links = bs_object \\\n",
    "        .find(\n",
    "            \"ul\",\n",
    "            {\"data-testid\": \"results\"}\n",
    "        ) \\\n",
    "        .findAll(\n",
    "            \"a\",\n",
    "            href=re.compile(f\"{BASE_URL}/*\") # the `*` denotes wildcard any\n",
    "        )\n",
    "\n",
    "    for link in index_links:\n",
    "        # if its a property address, add it to the list\n",
    "        if 'address' in link['class']:\n",
    "            url_links.append(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90057fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each url, scrape some basic metadata\n",
    "for property_url in url_links[1:]:\n",
    "    bs_object = BeautifulSoup(requests.get(property_url, headers=headers).text, \"html.parser\")\n",
    "\n",
    "    # looks for the header class to get property name\n",
    "    property_metadata[property_url]['name'] = bs_object \\\n",
    "        .find(\"h1\", {\"class\": \"css-164r41r\"}) \\\n",
    "        .text\n",
    "\n",
    "    # looks for the div containing a summary title for cost\n",
    "    property_metadata[property_url]['cost_text'] = bs_object \\\n",
    "        .find(\"div\", {\"data-testid\": \"listing-details__summary-title\"}) \\\n",
    "        .text\n",
    "\n",
    "    # looks for the div containing the number of bed, bathroom and parking area\n",
    "    property_metadata[property_url]['features'] = bs_object \\\n",
    "        .find(\"div\", {\"data-testid\": \"property-features-wrapper\"}) \\\n",
    "        .text\n",
    "    \n",
    "    # looks for the div containing the type of property\n",
    "    property_metadata[property_url]['type'] = bs_object \\\n",
    "        .find(\"div\", {\"data-testid\": \"listing-summary-property-type\"}) \\\n",
    "        .text\n",
    "    \n",
    "    # extract coordinates from the hyperlink provided\n",
    "    property_metadata[property_url]['coordinates'] = [\n",
    "        float(coord) for coord in re.findall(\n",
    "            r'destination=([-\\s,\\d\\.]+)', # use regex101.com here if you need to\n",
    "            bs_object \\\n",
    "                .find(\n",
    "                    \"a\",\n",
    "                    {\"target\": \"_blank\", 'rel': \"noopener noreferer\"}\n",
    "                ) \\\n",
    "                .attrs['href']\n",
    "        )[0].split(',')\n",
    "    ]\n",
    "\n",
    "    #property_metadata[property_url]['rooms'] = [\n",
    "    #    re.findall(r'\\d\\s[A-Za-z]+', feature.text)[0] for feature in bs_object \\\n",
    "    #        .find(\"div\", {\"data-testid\": \"property-features\"}) \\\n",
    "    #        .findAll(\"span\", {\"data-testid\": \"property-features-text-container\"})\n",
    "    #]\n",
    "\n",
    "    property_metadata[property_url]['desc'] = re \\\n",
    "        .sub(r'<br\\/>', '\\n', str(bs_object.find(\"p\"))) \\\n",
    "        .strip('</p >')\n",
    "\n",
    "# output to example json in data/raw/\n",
    "with open('../data/raw/feature.json', 'w') as f:\n",
    "    dump(property_metadata, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd23a93",
   "metadata": {},
   "source": [
    "## Scrape data sorted by Lowest price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc4099ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "BASE_URL = \"https://www.domain.com.au\"\n",
    "N_PAGES = range(1, 51) # update this to your liking\n",
    "\n",
    "# begin code\n",
    "url_links = []\n",
    "property_metadata = defaultdict(dict)\n",
    "\n",
    "# generate list of urls to visit\n",
    "for page in N_PAGES:\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"}\n",
    "    url = BASE_URL + f\"/rent/vic/?sort=price-asc&page={page}\"\n",
    "    bs_object = BeautifulSoup(requests.get(url, headers=headers).text, \"html.parser\")\n",
    "\n",
    "    # find the unordered list (ul) elements which are the results, then\n",
    "    # find all href (a) tags that are from the base_url website.\n",
    "    index_links = bs_object \\\n",
    "        .find(\n",
    "            \"ul\",\n",
    "            {\"data-testid\": \"results\"}\n",
    "        ) \\\n",
    "        .findAll(\n",
    "            \"a\",\n",
    "            href=re.compile(f\"{BASE_URL}/*\") # the `*` denotes wildcard any\n",
    "        )\n",
    "\n",
    "    for link in index_links:\n",
    "        # if its a property address, add it to the list\n",
    "        if 'address' in link['class']:\n",
    "            url_links.append(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "615aea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each url, scrape some basic metadata\n",
    "for property_url in url_links[1:]:\n",
    "    bs_object = BeautifulSoup(requests.get(property_url, headers=headers).text, \"html.parser\")\n",
    "\n",
    "    # looks for the header class to get property name\n",
    "    property_metadata[property_url]['name'] = bs_object \\\n",
    "        .find(\"h1\", {\"class\": \"css-164r41r\"}) \\\n",
    "        .text\n",
    "\n",
    "    # looks for the div containing a summary title for cost\n",
    "    property_metadata[property_url]['cost_text'] = bs_object \\\n",
    "        .find(\"div\", {\"data-testid\": \"listing-details__summary-title\"}) \\\n",
    "        .text\n",
    "\n",
    "    # looks for the div containing the number of bed, bathroom and parking area\n",
    "    property_metadata[property_url]['features'] = bs_object \\\n",
    "        .find(\"div\", {\"data-testid\": \"property-features-wrapper\"}) \\\n",
    "        .text\n",
    "    \n",
    "    # looks for the div containing the type of property\n",
    "    property_metadata[property_url]['type'] = bs_object \\\n",
    "        .find(\"div\", {\"data-testid\": \"listing-summary-property-type\"}) \\\n",
    "        .text\n",
    "    \n",
    "    # extract coordinates from the hyperlink provided\n",
    "    property_metadata[property_url]['coordinates'] = [\n",
    "        float(coord) for coord in re.findall(\n",
    "            r'destination=([-\\s,\\d\\.]+)', # use regex101.com here if you need to\n",
    "            bs_object \\\n",
    "                .find(\n",
    "                    \"a\",\n",
    "                    {\"target\": \"_blank\", 'rel': \"noopener noreferer\"}\n",
    "                ) \\\n",
    "                .attrs['href']\n",
    "        )[0].split(',')\n",
    "    ]\n",
    "\n",
    "    #property_metadata[property_url]['rooms'] = [\n",
    "    #    re.findall(r'\\d\\s[A-Za-z]+', feature.text)[0] for feature in bs_object \\\n",
    "    #        .find(\"div\", {\"data-testid\": \"property-features\"}) \\\n",
    "    #        .findAll(\"span\", {\"data-testid\": \"property-features-text-container\"})\n",
    "    #]\n",
    "\n",
    "    property_metadata[property_url]['desc'] = re \\\n",
    "        .sub(r'<br\\/>', '\\n', str(bs_object.find(\"p\"))) \\\n",
    "        .strip('</p >')\n",
    "\n",
    "# output to example json in data/raw/\n",
    "with open('../data/raw/lowest_prices.json', 'w') as f:\n",
    "    dump(property_metadata, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc117bd",
   "metadata": {},
   "source": [
    "## Scrape data sorted by Newest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f9211a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "BASE_URL = \"https://www.domain.com.au\"\n",
    "N_PAGES = range(1, 51) # update this to your liking\n",
    "\n",
    "# begin code\n",
    "url_links = []\n",
    "property_metadata = defaultdict(dict)\n",
    "\n",
    "# generate list of urls to visit\n",
    "for page in N_PAGES:\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"}\n",
    "    url = BASE_URL + f\"/rent/vic/?sort=dateupdated-desc&page={page}\"\n",
    "    bs_object = BeautifulSoup(requests.get(url, headers=headers).text, \"html.parser\")\n",
    "\n",
    "    # find the unordered list (ul) elements which are the results, then\n",
    "    # find all href (a) tags that are from the base_url website.\n",
    "    index_links = bs_object \\\n",
    "        .find(\n",
    "            \"ul\",\n",
    "            {\"data-testid\": \"results\"}\n",
    "        ) \\\n",
    "        .findAll(\n",
    "            \"a\",\n",
    "            href=re.compile(f\"{BASE_URL}/*\") # the `*` denotes wildcard any\n",
    "        )\n",
    "\n",
    "    for link in index_links:\n",
    "        # if its a property address, add it to the list\n",
    "        if 'address' in link['class']:\n",
    "            url_links.append(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f24a261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each url, scrape some basic metadata\n",
    "for property_url in url_links[1:]:\n",
    "    bs_object = BeautifulSoup(requests.get(property_url, headers=headers).text, \"html.parser\")\n",
    "\n",
    "    # looks for the header class to get property name\n",
    "    property_metadata[property_url]['name'] = bs_object \\\n",
    "        .find(\"h1\", {\"class\": \"css-164r41r\"}) \\\n",
    "        .text\n",
    "\n",
    "    # looks for the div containing a summary title for cost\n",
    "    property_metadata[property_url]['cost_text'] = bs_object \\\n",
    "        .find(\"div\", {\"data-testid\": \"listing-details__summary-title\"}) \\\n",
    "        .text\n",
    "\n",
    "    # looks for the div containing the number of bed, bathroom and parking area\n",
    "    property_metadata[property_url]['features'] = bs_object \\\n",
    "        .find(\"div\", {\"data-testid\": \"property-features-wrapper\"}) \\\n",
    "        .text\n",
    "    \n",
    "    # looks for the div containing the type of property\n",
    "    property_metadata[property_url]['type'] = bs_object \\\n",
    "        .find(\"div\", {\"data-testid\": \"listing-summary-property-type\"}) \\\n",
    "        .text\n",
    "    \n",
    "    # extract coordinates from the hyperlink provided\n",
    "    property_metadata[property_url]['coordinates'] = [\n",
    "        float(coord) for coord in re.findall(\n",
    "            r'destination=([-\\s,\\d\\.]+)', # use regex101.com here if you need to\n",
    "            bs_object \\\n",
    "                .find(\n",
    "                    \"a\",\n",
    "                    {\"target\": \"_blank\", 'rel': \"noopener noreferer\"}\n",
    "                ) \\\n",
    "                .attrs['href']\n",
    "        )[0].split(',')\n",
    "    ]\n",
    "\n",
    "    #property_metadata[property_url]['rooms'] = [\n",
    "    #    re.findall(r'\\d\\s[A-Za-z]+', feature.text)[0] for feature in bs_object \\\n",
    "    #        .find(\"div\", {\"data-testid\": \"property-features\"}) \\\n",
    "    #        .findAll(\"span\", {\"data-testid\": \"property-features-text-container\"})\n",
    "    #]\n",
    "\n",
    "    property_metadata[property_url]['desc'] = re \\\n",
    "        .sub(r'<br\\/>', '\\n', str(bs_object.find(\"p\"))) \\\n",
    "        .strip('</p >')\n",
    "\n",
    "# output to example json in data/raw/\n",
    "with open('../data/raw/newest.json', 'w') as f:\n",
    "    dump(property_metadata, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd19746",
   "metadata": {},
   "source": [
    "## Scrape data sorted by Suburb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3f508a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "BASE_URL = \"https://www.domain.com.au\"\n",
    "N_PAGES = range(1, 51) # update this to your liking\n",
    "\n",
    "# begin code\n",
    "url_links = []\n",
    "property_metadata = defaultdict(dict)\n",
    "\n",
    "# generate list of urls to visit\n",
    "for page in N_PAGES:\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"}\n",
    "    url = BASE_URL + f\"/rent/vic/?sort=suburb-asc&page={page}\"\n",
    "    bs_object = BeautifulSoup(requests.get(url, headers=headers).text, \"html.parser\")\n",
    "\n",
    "    # find the unordered list (ul) elements which are the results, then\n",
    "    # find all href (a) tags that are from the base_url website.\n",
    "    index_links = bs_object \\\n",
    "        .find(\n",
    "            \"ul\",\n",
    "            {\"data-testid\": \"results\"}\n",
    "        ) \\\n",
    "        .findAll(\n",
    "            \"a\",\n",
    "            href=re.compile(f\"{BASE_URL}/*\") # the `*` denotes wildcard any\n",
    "        )\n",
    "\n",
    "    for link in index_links:\n",
    "        # if its a property address, add it to the list\n",
    "        if 'address' in link['class']:\n",
    "            url_links.append(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f4b0e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each url, scrape some basic metadata\n",
    "for property_url in url_links[1:]:\n",
    "    bs_object = BeautifulSoup(requests.get(property_url, headers=headers).text, \"html.parser\")\n",
    "\n",
    "    # looks for the header class to get property name\n",
    "    property_metadata[property_url]['name'] = bs_object \\\n",
    "        .find(\"h1\", {\"class\": \"css-164r41r\"}) \\\n",
    "        .text\n",
    "\n",
    "    # looks for the div containing a summary title for cost\n",
    "    property_metadata[property_url]['cost_text'] = bs_object \\\n",
    "        .find(\"div\", {\"data-testid\": \"listing-details__summary-title\"}) \\\n",
    "        .text\n",
    "\n",
    "    # looks for the div containing the number of bed, bathroom and parking area\n",
    "    property_metadata[property_url]['features'] = bs_object \\\n",
    "        .find(\"div\", {\"data-testid\": \"property-features-wrapper\"}) \\\n",
    "        .text\n",
    "    \n",
    "    # looks for the div containing the type of property\n",
    "    property_metadata[property_url]['type'] = bs_object \\\n",
    "        .find(\"div\", {\"data-testid\": \"listing-summary-property-type\"}) \\\n",
    "        .text\n",
    "    \n",
    "    # extract coordinates from the hyperlink provided\n",
    "    property_metadata[property_url]['coordinates'] = [\n",
    "        float(coord) for coord in re.findall(\n",
    "            r'destination=([-\\s,\\d\\.]+)', # use regex101.com here if you need to\n",
    "            bs_object \\\n",
    "                .find(\n",
    "                    \"a\",\n",
    "                    {\"target\": \"_blank\", 'rel': \"noopener noreferer\"}\n",
    "                ) \\\n",
    "                .attrs['href']\n",
    "        )[0].split(',')\n",
    "    ]\n",
    "\n",
    "    #property_metadata[property_url]['rooms'] = [\n",
    "    #    re.findall(r'\\d\\s[A-Za-z]+', feature.text)[0] for feature in bs_object \\\n",
    "    #        .find(\"div\", {\"data-testid\": \"property-features\"}) \\\n",
    "    #        .findAll(\"span\", {\"data-testid\": \"property-features-text-container\"})\n",
    "    #]\n",
    "\n",
    "    property_metadata[property_url]['desc'] = re \\\n",
    "        .sub(r'<br\\/>', '\\n', str(bs_object.find(\"p\"))) \\\n",
    "        .strip('</p >')\n",
    "\n",
    "# output to example json in data/raw/\n",
    "with open('../data/raw/suburb.json', 'w') as f:\n",
    "    dump(property_metadata, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
