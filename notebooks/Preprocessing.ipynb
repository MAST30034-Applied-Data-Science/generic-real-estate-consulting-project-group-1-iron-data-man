{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4cbda5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import folium\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import haversine as hs\n",
    "from haversine import Unit\n",
    "from datetime import datetime\n",
    "import openrouteservice as ors\n",
    "from difflib import SequenceMatcher\n",
    "from IPython.display import display\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import geopy\n",
    "import googlemaps\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "from geopy.extra.rate_limiter import RateLimiter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7cca53",
   "metadata": {},
   "source": [
    "## Get API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95227f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/raw/APIkeys.txt') as file:\n",
    "    api_keys = file.readlines()\n",
    "    api_keys = [key.rstrip() for key in api_keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9ea332",
   "metadata": {},
   "source": [
    "## Merge Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac726e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset after data-cleaning\n",
    "external = pd.read_csv('../data/curated/external.csv', low_memory = False)\n",
    "property_df = pd.read_csv('../data/curated/cleaned_property_data.csv', low_memory = False)\n",
    "rental = pd.read_csv('../data/curated/rental_median.csv', low_memory = False)\n",
    "GNR = pd.read_csv('../data/curated/GNR_cleaned.csv', low_memory = False)\n",
    "count_table = pd.read_csv('../data/curated/count_table.csv', low_memory = False)\n",
    "\n",
    "#read postcode match suburb\n",
    "with open('../data/raw/postcode_match_suburb.json') as json_data:\n",
    "    data = json.load(json_data)\n",
    "postcode_match = pd.DataFrame.from_dict({'postcode':data.keys(), 'suburb':data.values()})\n",
    "postcode_match['postcode'] = pd.to_numeric(postcode_match['postcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a4f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all dataframe\n",
    "display(external.head(10))\n",
    "display(property_df.head(10))\n",
    "display(rental.head(10))\n",
    "display(GNR.head(10))\n",
    "display(postcode_match.head(10))\n",
    "property_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94601bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the all types of property data\n",
    "property_df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce71421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete some unsusal data, treat them as outlier\n",
    "property_df = property_df[property_df['type'] != 'Carspace']\n",
    "property_df = property_df[property_df['type'] != 'Retirement']\n",
    "property_df = property_df[property_df['type'] != 'Farm']\n",
    "property_df = property_df[property_df['type'] != 'Acreage / Semi-Rural']\n",
    "property_df = property_df[property_df['type'] != 'Rural']\n",
    "property_df = property_df[property_df['type'] != 'New House & Land']\n",
    "# re-classify the property data\n",
    "property_df['type'] = property_df['type'].replace('Villa','House')\n",
    "property_df['type'] = property_df['type'].replace('Semi-Detached','House')\n",
    "property_df['type'] = property_df['type'].replace('Duplex','House')\n",
    "property_df['type'] = property_df['type'].replace('New Apartments / Off the Plan','Apartment / Unit / Flat')\n",
    "property_df['type'] = property_df['type'].replace('Terrace','Apartment / Unit / Flat')\n",
    "property_df = property_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0f6f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the address and get the suburbs\n",
    "def extract_suburb(address):\n",
    "    address = address.split(\" \")\n",
    "    if address[-3].isdigit():\n",
    "        return address[-4]\n",
    "    else:\n",
    "        return address[-3]\n",
    "property_df['suburb'] = property_df[\"address\"].apply(extract_suburb)\n",
    "property_df['suburb'] = property_df['suburb'].str.upper()  # make letter upper \n",
    "property_df['postcode'] = pd.to_numeric(property_df['postcode'])  # make sure the postcodes are int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf561424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the feature we need\n",
    "property_df = property_df[['address', 'rent_weekly', 'floor', 'suburb','postcode', 'type', 'furnitured', 'pool',\n",
    "                           'gym', 'num_bed', 'num_bath', 'num_car_park', 'coordinates']]\n",
    "# convert coordinates from str to list\n",
    "property_df['coordinates'] = property_df['coordinates'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27186e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca730c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the similarity percentage\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# find the most similar suburb\n",
    "def most_similar(df,suburb):\n",
    "    if df['suburb'].shape[0] == 1:\n",
    "        current_match = [100,df['suburb'].iloc[0][0]]\n",
    "    else:\n",
    "        # initialize the most similar suburb\n",
    "        current_match = [0,\"None\"]\n",
    "        # check similarity for each suburb\n",
    "        for sub in df['suburb']:\n",
    "            # get the similarity percentage\n",
    "            simi_percent = similar(suburb, sub)\n",
    "            # update most similar suburb\n",
    "            if simi_percent > current_match[0]:\n",
    "                current_match = [simi_percent, sub]\n",
    "    # return the most similar suburb\n",
    "    return current_match[1]\n",
    "\n",
    "def correct_suburb(suburb_df, property_df):\n",
    "    # check property_df each row's suburb\n",
    "    for row in range(property_df.shape[0]):\n",
    "        # get the property postcode\n",
    "        postcode = property_df.loc[row, 'postcode']\n",
    "        # get the postcode and corresponding suburbs\n",
    "        match_df = suburb_df[suburb_df['postcode'] == postcode]\n",
    "        sub_lis = list(match_df['suburb'])[0]\n",
    "        # if the suburb matched, don't change it\n",
    "        if property_df.loc[row, 'suburb'] in sub_lis:\n",
    "            pass\n",
    "        # if the suburb don't matched, replace by the most similar suburb by postcode\n",
    "        else:\n",
    "            most_match = most_similar(match_df, property_df.loc[row, 'suburb'])\n",
    "            property_df.at[row, 'suburb'] = most_match\n",
    "    return property_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8689b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct the suburb names in property data\n",
    "property_df = correct_suburb(postcode_match,property_df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb1a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8414f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the retal columns' names\n",
    "rental.columns = ['suburb' if x=='Suburb' else x for x in rental.columns]\n",
    "# make letter upper\n",
    "rental['suburb'] = rental['suburb'].str.upper()\n",
    "# let CBD represent MELBOURNE 3000\n",
    "rental = rental.replace('CBD', 'MELBOURNE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18cc084",
   "metadata": {},
   "outputs": [],
   "source": [
    "rental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62abba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the position of \"EAST\",\"WEST\",\"NORTH\",\"SOUTH\" for some cases\n",
    "def change_word_position(suburb):\n",
    "    # split the suburb by space\n",
    "    suburb_lis = suburb.split(\" \")\n",
    "    name =\"\"\n",
    "    # if the suburb name contains more than one word\n",
    "    # then we need to have check the positions of [\"EAST\",\"WEST\",\"NORTH\",\"SOUTH\"]\n",
    "    if len(suburb_lis) >= 2:\n",
    "        if suburb_lis[0] in [\"EAST\",\"WEST\",\"NORTH\",\"SOUTH\"]:\n",
    "            # if the suburb name contains words below, then doesn't need to change the position\n",
    "            if suburb_lis[1] not in [\"MELBOURNE\",'GEELONG','BENDIGO','YEOBURN','WANGARATTA','WARBURTON','SALE',\n",
    "                                     'BAIRNSDALE','YARRA','FOOTSCRAY']:\n",
    "                # make the word of [\"EAST\",\"WEST\",\"NORTH\",\"SOUTH\"] at the end of suburb name\n",
    "                for i in range(1,len(suburb_lis)):\n",
    "                    name+=(str(suburb_lis[i])+\" \")\n",
    "                name+=str(suburb_lis[0])\n",
    "            # otherwise, doesn't need to change suburb name\n",
    "            else:\n",
    "                name = suburb\n",
    "        else:\n",
    "            name = suburb\n",
    "    else:\n",
    "        name = suburb\n",
    "    return name\n",
    "rental['suburb'] = rental['suburb'].apply(change_word_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9935ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the most similar suburb names for rental data\n",
    "def correct_suburb(suburb_df, df):\n",
    "    # check property_df each row's suburb\n",
    "    for row in range(df.shape[0]):\n",
    "        # all the suburb names\n",
    "        sub_lis = list(set(suburb_df.suburb.sum()))\n",
    "        # if the suburb matched, don't change it\n",
    "        if df.loc[row, 'suburb'] in sub_lis:\n",
    "            pass\n",
    "        # if the suburb don't matched, replace by the most similar suburb by postcode\n",
    "        else:\n",
    "            most_match = most_similar(pd.DataFrame.from_dict({'suburb':sub_lis}), df.loc[row, 'suburb'])\n",
    "            df.at[row, 'suburb'] = most_match\n",
    "    return df\n",
    "rental = correct_suburb(postcode_match,rental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79c9f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge rental data and property_df\n",
    "property_df = pd.merge(property_df, rental, on='suburb', how='left').fillna(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007f4071",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db7b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b10eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge count_table data and property_df\n",
    "property_df = pd.merge(property_df, count_table, on='suburb', how='left').fillna(np.nan)\n",
    "property_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e57ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df.to_csv('../data/curated/final_property.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722a1073",
   "metadata": {},
   "source": [
    "# calculate distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82662689",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df = pd.read_csv('../data/curated/final_property.csv', low_memory=False)\n",
    "property_df['coordinates'] = property_df['coordinates'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7171c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the distance bewteen two points are smaller or equal to 1.5 km\n",
    "def around_1500m(loc, df):\n",
    "    max_long = loc[1] + 0.01\n",
    "    min_long = loc[1] - 0.01\n",
    "    max_lan = loc[0] + 0.01\n",
    "    min_lan = loc[0] - 0.01\n",
    "    \n",
    "    df = df[df['LONGITUDE'] <= max_long]\n",
    "    df = df[df['LONGITUDE'] >= min_long]\n",
    "    df = df[df['LATITUDE'] <= max_lan]\n",
    "    df = df[df['LATITUDE'] >= min_lan]\n",
    "    return df\n",
    "\n",
    "# check if the distance bewteen two points are smaller or equal to 2 km\n",
    "def around_2km(loc, df):\n",
    "    max_long = loc[1] + 0.015\n",
    "    min_long = loc[1] - 0.015\n",
    "    max_lan = loc[0] + 0.015\n",
    "    min_lan = loc[0] - 0.015\n",
    "\n",
    "    df = df[df['LONGITUDE'] <= max_long]\n",
    "    df = df[df['LONGITUDE'] >= min_long]\n",
    "    df = df[df['LATITUDE'] <= max_lan]\n",
    "    df = df[df['LATITUDE'] >= min_lan]\n",
    "    return df\n",
    "\n",
    "# check if the distance bewteen two points are smaller or equal to 3 km\n",
    "def around_3km(loc, df):\n",
    "    max_long = loc[1] + 0.02\n",
    "    min_long = loc[1] - 0.02\n",
    "    max_lan = loc[0] + 0.02\n",
    "    min_lan = loc[0] - 0.02\n",
    "\n",
    "    df = df[df['LONGITUDE'] <= max_long]\n",
    "    df = df[df['LONGITUDE'] >= min_long]\n",
    "    df = df[df['LATITUDE'] <= max_lan]\n",
    "    df = df[df['LATITUDE'] >= min_lan]\n",
    "    return df\n",
    "\n",
    "# comparing the distances and record three cloest points\n",
    "def cloest_point(dist_dict,dist,loc,stop):\n",
    "    # if there is no point, then just append the point into dict\n",
    "    if len(dist_dict) < 2:\n",
    "        dist_dict.append((dist,loc,stop))\n",
    "    # if there already has three points, then compares distance\n",
    "    else:\n",
    "        # if the current distance smaller than records' distance\n",
    "        if dist < dist_dict[0][0]:\n",
    "            # delete the record point\n",
    "            dist_dict.pop(0)\n",
    "            # append new cloest point\n",
    "            dist_dict.append((dist,loc,stop))\n",
    "        elif dist < dist_dict[1][0]:\n",
    "            # delete the record point\n",
    "            dist_dict.pop(1)\n",
    "            # append new cloest point\n",
    "            dist_dict.append((dist,loc,stop))\n",
    "    return dist_dict\n",
    "            \n",
    "# calculate the cloest three train station for each property data\n",
    "def distance_train(loc1):\n",
    "    # read train station data\n",
    "    GNR = pd.read_csv('../data/curated/GNR_cleaned.csv', low_memory = False)\n",
    "    # initaliza the dict for record the cloest three point of interest\n",
    "    dist_lis = []\n",
    "    # read train station data\n",
    "    train = GNR[GNR['FEATURE'] == 'TRAIN STATION']\n",
    "    train = around_3km(loc1, train)\n",
    "    # if there is not any train station within 3 km straight line distance, it should return empty list\n",
    "    if train.shape[0] == 0:\n",
    "        dist_lis = []\n",
    "    else:\n",
    "        # extact all features\n",
    "        train_stop = list(train[\"PLACE_NAME\"].unique())\n",
    "        # find cloest three points\n",
    "        for i in range(train.shape[0]):\n",
    "            # feature points\n",
    "            loc2 = (train.iloc[i][\"LATITUDE\"],train.iloc[i][\"LONGITUDE\"])\n",
    "            # calculate distance between property and feature\n",
    "            dist = hs.haversine(loc1,loc2,unit=Unit.METERS)\n",
    "            # check the cloest\n",
    "            dist_lis = cloest_point(dist_lis,dist,loc2,train.iloc[i][\"PLACE_NAME\"])\n",
    "    return dist_lis\n",
    "\n",
    "# calculate the cloest three bus stop for each property data\n",
    "def distance_bus(loc1):\n",
    "    # read train station data\n",
    "    GNR = pd.read_csv('../data/curated/GNR_cleaned.csv', low_memory = False)\n",
    "    # initaliza the dict for record the cloest three point of interest\n",
    "    dist_lis = []\n",
    "    # read train station data\n",
    "    bus = GNR[GNR['FEATURE'] == 'BUS']\n",
    "    bus = around_1500m(loc1, bus)\n",
    "    # if there is not any bus stop within 1.5 km straight line distance, it should return empty list\n",
    "    if bus.shape[0] == 0:\n",
    "        dist_lis = []\n",
    "    else:\n",
    "        # extact all features\n",
    "        bus_stop = list(bus[\"PLACE_NAME\"].unique())\n",
    "        # find cloest three points\n",
    "        for i in range(bus.shape[0]):\n",
    "            # feature points\n",
    "            loc2 = (bus.iloc[i][\"LATITUDE\"],bus.iloc[i][\"LONGITUDE\"])\n",
    "            # calculate distance between property and feature\n",
    "            dist = hs.haversine(loc1,loc2,unit=Unit.METERS)\n",
    "            # check the cloest\n",
    "            dist_lis = cloest_point(dist_lis,dist,loc2,bus.iloc[i][\"PLACE_NAME\"])\n",
    "    return dist_lis\n",
    "\n",
    "# calculate the cloest three tram stop for each property data\n",
    "def distance_tram(loc1):\n",
    "    # read train station data\n",
    "    GNR = pd.read_csv('../data/curated/GNR_cleaned.csv', low_memory = False)\n",
    "    # initaliza the dict for record the cloest three point of interest\n",
    "    dist_lis = []\n",
    "    # read train station data\n",
    "    tram = GNR[GNR['FEATURE'] == 'TRAM STATION']\n",
    "    tram = around_2km(loc1, tram)\n",
    "    # if there is not any bus stop within 2 km straight line distance, it should return empty list\n",
    "    if tram.shape[0] == 0:\n",
    "        dist_lis = []\n",
    "    else:\n",
    "        # extact all features\n",
    "        tram_stop = list(tram[\"PLACE_NAME\"].unique())\n",
    "        # find cloest three points\n",
    "        for i in range(tram.shape[0]):\n",
    "            # feature points\n",
    "            loc2 = (tram.iloc[i][\"LATITUDE\"],tram.iloc[i][\"LONGITUDE\"])\n",
    "            # calculate distance between property and feature\n",
    "            dist = hs.haversine(loc1,loc2,unit=Unit.METERS)\n",
    "            # check the cloest\n",
    "            dist_lis = cloest_point(dist_lis,dist,loc2,tram.iloc[i][\"PLACE_NAME\"])\n",
    "    return dist_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99841484",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=datetime.now()\n",
    "# find the cloest train station\n",
    "property_df['cloest_train_station'] = property_df[\"coordinates\"].apply(distance_train)\n",
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2db190",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=datetime.now()\n",
    "# find the cloest tram stop\n",
    "property_df['cloest_tram_stop'] = property_df[\"coordinates\"].apply(distance_tram)\n",
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df2793",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=datetime.now()\n",
    "# find the cloest bus stop\n",
    "property_df['cloest_bus_stop'] = property_df[\"coordinates\"].apply(distance_bus)\n",
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca26dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df['cloest_train_station'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d7029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a08f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df.to_csv('../data/curated/property_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff7e39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b132a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put two coordinate in and return the duration between two coordinates\n",
    "# coordinate form [longitude, latitude]\n",
    "def calculate_distance_between_coordinates(coordinate1, coordinate2, api_key):\n",
    "\n",
    "    # connect open route service\n",
    "    client = ors.Client(key = api_key)\n",
    "\n",
    "    # put two coordinates in list\n",
    "    cor = [(coordinate1[1],coordinate1[0]), (coordinate2[1],coordinate2[0])]\n",
    "\n",
    "    # using open route service\n",
    "    route = client.directions(\n",
    "    coordinates= cor,\n",
    "    profile='driving-car',\n",
    "    format='geojson',\n",
    "    )\n",
    "    \n",
    "    time.sleep(1.5)\n",
    "\n",
    "    # dict of distance and duration\n",
    "    dist = route['features'][0]['properties']['segments'][0]['distance']\n",
    "    duration = route['features'][0]['properties']['segments'][0]['duration']\n",
    "    \n",
    "    # return the duration\n",
    "    return dist, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dc0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_driving(coor,lis,api_key):\n",
    "    result ={\"dist\":[],\"name\":[],\"duration\":[]}\n",
    "    # first point\n",
    "    dist, duration = calculate_distance_between_coordinates(coor,lis[0][1],api_key)\n",
    "    result['dist'].append(dist)\n",
    "    result['name'].append(lis[0][2])\n",
    "    result['duration'].append(duration)\n",
    "    \n",
    "    # second point\n",
    "    dist, duration = calculate_distance_between_coordinates(coor,lis[1][1],api_key)\n",
    "    result['dist'].append(dist)\n",
    "    result['name'].append(lis[1][2])\n",
    "    result['duration'].append(duration)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3e698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#property_df.at[row, 'suburb'] = most_match\n",
    "            \n",
    "def transportation_time(df,api1,api2,api3):\n",
    "    train = []\n",
    "    tram = []\n",
    "    bus =[]\n",
    "    for row in df.index.to_list():\n",
    "        train.append(find_driving(df.loc[row, 'coordinates'],df.loc[row, 'cloest_train_station'],api1))\n",
    "        tram.append(find_driving(df.loc[row, 'coordinates'],df.loc[row, 'cloest_tram_stop'],api2))\n",
    "        bus.append(find_driving(df.loc[row, 'coordinates'],df.loc[row, 'cloest_bus_stop'],api3))\n",
    "    df['driving_to_train'] = train\n",
    "    df['driving_to_tram'] = tram\n",
    "    df['driving_to_bus'] = bus\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e15768",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df['cloest_tram_stop'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f7e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gmaps = googlemaps.Client(key='AIzaSyAwGu0E8STeETxFXmrL0UjyeF7mFRAn_5k')\n",
    "now = datetime.now()\n",
    "for i in property_df.shape[0]:\n",
    "    properity_coor = property_df['coordinates'][i]\n",
    "    closest_train_station = property_df['cloest_train_station'][i][0][1]\n",
    "    closest_tram_stop = property_df['cloest_tram_stop'][i][0][1]\n",
    "    closest_bus_stop = property_df['cloest_bus_stop'][i][0][1]\n",
    "\n",
    "    \n",
    "directions_result = gmaps.directions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a8f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# google map code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "16343f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(208.7885192155693, (-37.811981, 144.955654), 'Flagstaff Railway Station (Melbourne City)'), (521.9037087436633, (-37.809939, 144.962594), 'Melbourne Central Railway Station (Melbourne City)')]\""
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "property_df = pd.read_csv('../data/curated/property_cleaned.csv', low_memory = False)\n",
    "property_df['cloest_train_station'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f56c02c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'['"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "property_df['cloest_train_station'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the travel time bewteen the property and its corresponding closest train station\n",
    "final_direction_result = []\n",
    "gmaps = googlemaps.Client(key='AIzaSyAwGu0E8STeETxFXmrL0UjyeF7mFRAn_5k')\n",
    "now = datetime.now()\n",
    "for i in range(property_df.shape[0]):\n",
    "    properity_coor = property_df['coordinates'][i]\n",
    "    if len(property_df['cloest_train_station'][i]) < 1:\n",
    "        final_direction_result.append(-1)\n",
    "        pass\n",
    "    else:\n",
    "        closest_train_station = property_df['cloest_train_station'][i][0][1]\n",
    "        directions_result = gmaps.directions(properity_coor, closest_train_station, mode='driving', departure_time=now)\n",
    "        final_direction_result.append(directions_result)\n",
    "final_direction_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e39858",
   "metadata": {},
   "outputs": [],
   "source": [
    "properity_coor = property_df['coordinates'][0]\n",
    "closest_train_station = property_df['cloest_train_station'][0][0][1]\n",
    "gmaps = googlemaps.Client(key='AIzaSyAwGu0E8STeETxFXmrL0UjyeF7mFRAn_5k')\n",
    "now = datetime.now()\n",
    "directions_result = gmaps.directions(properity_coor, closest_train_station, mode='driving', departure_time=now)\n",
    "directions_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776892df",
   "metadata": {},
   "outputs": [],
   "source": [
    "properity_coor = property_df['coordinates'][0]\n",
    "properity_coor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c8ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eeea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "# reverse the coordinates by small size due to request limitation\n",
    "i = 0\n",
    "key = 0\n",
    "while i < 10000:\n",
    "    if i < 9000:\n",
    "        df_i = property_df.copy().iloc[i:i+2000]\n",
    "        df_i = transportation_time(df_i,api_keys[key],api_keys[key+1],api_keys[key+2])\n",
    "        df = pd.concat([df ,df_i],ignore_index=True)\n",
    "    else:\n",
    "        \n",
    "        df_i = property_df.copy().iloc[i:]\n",
    "        df_i = transportation_time(df_i,api_keys[key],api_keys[key+1],api_keys[key+2])\n",
    "        df = pd.concat([df ,df_i],ignore_index=True)\n",
    "    print(i)\n",
    "    i+=2000\n",
    "    key+=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108537b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesy = transportation_time(test,api_keys[0])\n",
    "tesy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d235d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f42ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['driving_to_train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98279dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be66fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6447495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ac869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84bb699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b008a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfdef76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf29f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84de1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a228912f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bbb333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b1c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ac214c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e0ffe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd7810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read rental data\n",
    "path = os.getcwd().replace(\"notebooks\",\"\") + \"data/curated/\"\n",
    "train = pd.read_csv(path+'train_station.csv', low_memory = False)\n",
    "property_df = pd.read_csv(path+'cleaned_rent.csv', low_memory = False)\n",
    "train[\"coordinates\"] = list(zip(train.LATITUDE, train.LONGITUDE))\n",
    "#GNR = GNR.drop_duplicates(subset='coordinates', keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601ce549",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf6591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine longtitude and latitude to coordnates and use first 10 property data as sample\n",
    "property_df[\"coordinates\"] = list(zip(property_df.latitude, property_df.longitude))\n",
    "property_df = property_df.iloc[:10]\n",
    "property_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ddf9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# comparing the distances and record three cloest points\n",
    "def cloest_point(dist_dict,dist,loc,stop):\n",
    "    # if there is no point, then just append the point into dict\n",
    "    if len(dist_dict) < 3:\n",
    "        dist_dict.append((dist,loc,stop))\n",
    "    # if there already has three points, then compares distance\n",
    "    else:\n",
    "        # if the current distance smaller than records' distance\n",
    "        if dist < dist_dict[0][0]:\n",
    "            # delete the record point\n",
    "            dist_dict.pop(0)\n",
    "            # append new cloest point\n",
    "            dist_dict.append((dist,loc,stop))\n",
    "        elif dist < dist_dict[1][0]:\n",
    "            # delete the record point\n",
    "            dist_dict.pop(1)\n",
    "            # append new cloest point\n",
    "            dist_dict.append((dist,loc,stop))\n",
    "        elif dist < dist_dict[2][0]:\n",
    "            # delete the record point\n",
    "            dist_dict.pop(2)\n",
    "            # append new cloest point\n",
    "            dist_dict.append((dist,loc,stop))\n",
    "    return dist_dict\n",
    "            \n",
    "# calculate the cloest three point of interest for each property data\n",
    "def distance(loc1):\n",
    "    # read train station data\n",
    "    train = pd.read_csv(path+'train_station.csv', low_memory = False)\n",
    "    # extact all features\n",
    "    train_stop = list(train[\"STOP_NAME\"].unique())\n",
    "    # initaliza the dict for record the cloest three point of interest\n",
    "    dist_lis = []\n",
    "    # find cloest three points\n",
    "    for i in range(train.shape[0]):\n",
    "        # feature points\n",
    "        loc2 = (train.iloc[i][\"LATITUDE\"],train.iloc[i][\"LONGITUDE\"])\n",
    "        # calculate distance between property and feature\n",
    "        dist = hs.haversine(loc1,loc2,unit=Unit.METERS)\n",
    "        # check the cloest\n",
    "        dist_lis = cloest_point(dist_lis,dist,loc2,train.iloc[i][\"STOP_NAME\"])\n",
    "    return dist_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c11f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df[\"train_station\"]= property_df[\"coordinates\"].apply(distance)  # calculate distance for each property row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904bc712",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea56733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df[\"train_station\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5819c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put two coordinate in and return the duration between two coordinates\n",
    "# coordinate form [longitude, latitude]\n",
    "def calculate_distance_between_coordinates(coordinate1, coordinate2):\n",
    "\n",
    "    # put your own open route service api key in here\n",
    "    api_key_openrouteservice = '5b3ce3597851110001cf6248d864908ae526479e86e6f4dd70971a37'\n",
    "\n",
    "    # connect open route service\n",
    "    client = ors.Client(key = api_key_openrouteservice)\n",
    "\n",
    "    # put two coordinates in list\n",
    "    cor = [coordinate1, coordinate2]\n",
    "\n",
    "    # using open route service\n",
    "    route = client.directions(\n",
    "    coordinates= cor,\n",
    "    profile='driving-car',\n",
    "    format='geojson',\n",
    "    )\n",
    "\n",
    "    # dict of distance and duration\n",
    "    dist = route['features'][0]['properties']['segments'][0]['distance']\n",
    "    duration = route['features'][0]['properties']['segments'][0]['duration']\n",
    "    \n",
    "    # return the duration\n",
    "    return dist, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ce2487",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_train_list = []\n",
    "nearest_distance_list = []\n",
    "nearest_duration_list = []\n",
    "for i in range(len(property_df)):\n",
    "    # print(i)\n",
    "    long = property_df[\"longitude\"][i]\n",
    "    lat = property_df[\"latitude\"][i]\n",
    "    property_coordinate = [long, lat]\n",
    "\n",
    "    # print(property_coordinate)\n",
    "\n",
    "    train = property_df[\"train_station\"][i]\n",
    "\n",
    "    duration = []\n",
    "    distance = []\n",
    "\n",
    "    for j in range(len(train)):\n",
    "        train_coord = train[j][1]\n",
    "        train_long = train_coord[1]\n",
    "        train_lat = train_coord[0]\n",
    "\n",
    "        train_position = [train_long, train_lat]\n",
    "        # print(train_position)\n",
    "        dist_in_between, duration_in_detween = calculate_distance_between_coordinates(property_coordinate, train_position)\n",
    "\n",
    "        duration.append(duration_in_detween)\n",
    "        distance.append(dist_in_between)\n",
    "    \n",
    "    for k in range(1, len(duration)):\n",
    "        if duration[k-1] <= duration[k]:\n",
    "            nearest_point_index = k-1\n",
    "            nearest_duration = duration[k-1]\n",
    "            nearest_distance = distance[k-1]\n",
    "\n",
    "        else:\n",
    "            nearest_point_index = k\n",
    "            nearest_duration = duration[k]\n",
    "            nearest_distance = distance[k]\n",
    "\n",
    "    nearest_train = train[nearest_point_index]\n",
    "    print(nearest_train)\n",
    "    nearest_train_list.append(nearest_train[2])\n",
    "    nearest_distance_list.append(nearest_distance)\n",
    "    nearest_duration_list.append(nearest_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e4a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df[\"nearest_train\"] = nearest_train_list\n",
    "property_df[\"nearest_distance(m)\"] = nearest_distance_list\n",
    "property_df[\"nearest_duration(s)\"] = nearest_duration_list\n",
    "property_df = property_df[['address','coordinates', 'train_station', 'nearest_train','nearest_distance(m)', 'nearest_duration(s)']]\n",
    "\n",
    "property_df.to_csv(\"../data/curated/dist_property_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b9aaad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec8d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06d649a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f1283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d80a66d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1584cb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0656f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c402993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd57628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe827f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be8f047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64090e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8adf20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd326ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e2594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50be6105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7789e50c",
   "metadata": {},
   "source": [
    "#### for further coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ef8df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(loc1, train_points):\n",
    "    for point in train_points:\n",
    "        dist, duration = calculate_distance_between_coordinates(loc1,point[1])\n",
    "    return dist, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d6697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a dict for each property data that contains distance and coordination of cloest three features\n",
    "def generate_dict(features):\n",
    "    dist_lis = {}\n",
    "    # initialize feature\n",
    "    for feature in features:\n",
    "        dist_lis[feature] = []\n",
    "    return dist_lis\n",
    "\n",
    "# comparing the distances and record three cloest points\n",
    "def cloest_point(point,dist_dict,dist,loc):\n",
    "    # if there is no point, then just append the point into dict\n",
    "    if len(dist_dict[point[\"FEATURE\"]]) < 3:\n",
    "        dist_dict[point[\"FEATURE\"]].append((dist,loc,point[\"PLACE_NAME\"]))\n",
    "    # if there already has three points, then compares distance\n",
    "    else:\n",
    "        # if the current distance smaller than records' distance\n",
    "        if dist < dist_dict[point[\"FEATURE\"]][0][0]:\n",
    "            # delete the record point\n",
    "            dist_dict[point[\"FEATURE\"]].pop(0)\n",
    "            # append new cloest point\n",
    "            dist_dict[point[\"FEATURE\"]].append((dist,loc,point[\"PLACE_NAME\"]))\n",
    "        elif dist < dist_dict[point[\"FEATURE\"]][1][0]:\n",
    "            # delete the record point\n",
    "            dist_dict[point[\"FEATURE\"]].pop(1)\n",
    "            # append new cloest point\n",
    "            dist_dict[point[\"FEATURE\"]].append((dist,loc,point[\"PLACE_NAME\"]))\n",
    "        elif dist < dist_dict[point[\"FEATURE\"]][2][0]:\n",
    "            # delete the record point\n",
    "            dist_dict[point[\"FEATURE\"]].pop(2)\n",
    "            # append new cloest point\n",
    "            dist_dict[point[\"FEATURE\"]].append((dist,loc,point[\"PLACE_NAME\"]))\n",
    "    return dist_dict\n",
    "            \n",
    "# calculate the cloest three point of interest for each property data\n",
    "def distance(loc1):\n",
    "    # read point of interest data\n",
    "    GNR = pd.read_csv(path+'GNR_suburb.csv', low_memory = False)\n",
    "    # extact all features\n",
    "    Point_of_Interest = list(GNR[\"FEATURE\"].unique())\n",
    "    # initaliza the dict for record the cloest three point of interest\n",
    "    dist_lis = generate_dict(Point_of_Interest)\n",
    "    # find cloest three points\n",
    "    for feature in Point_of_Interest:\n",
    "        df = GNR[GNR[\"FEATURE\"] == feature]  # select feature data\n",
    "        # calculate  distances for all feature points\n",
    "        for i in range(df.shape[0]):\n",
    "            # feature points\n",
    "            loc2 = (df.iloc[i][\"LATITUDE\"],df.iloc[i][\"LONGITUDE\"])\n",
    "            # calculate distance between property and feature\n",
    "            dist = hs.haversine(loc1,loc2,unit=Unit.METERS)\n",
    "            # check the cloest\n",
    "            dist_lis = cloest_point(df.iloc[i],dist_lis,dist,loc2)\n",
    "    return dist_lis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
